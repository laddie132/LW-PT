# config file

dataset:
  h5_path: data/rmsc.h5
  data_path: data/rmsc.pickle
  meta_data_path: data/rmsc.pickle.meta
  doc_rep_path: data/rmsc_doc_qt_rep.pt-ln-5k

  embedding_path: data/rmsc_word2vec.model.wv.vectors.npy
  embedding_freeze: True

global:
  random_seed: 123
  num_data_workers: 16

  max_sent_length: 20
  max_sent_num: 40
  max_doc_length: 500
  cand_doc_size: 4

  hierarchical: True  # same as the model

model:
  encoder: HLWAN    # BiGRU, LWBiGRU, HAN, HLWAN
  decoder: LinearMLC  # LinearMLC, LabelGraphMLC, LabelWiseMLC, LabelGraphWiseMLC

  use_pretrain: True
  embedding_num: 50000
  embedding_dim: 100

  hidden_size: 100
  label_size: 22
  dropout_p: 0.2
  layer_norm: true

train:
  num_epochs: 30
  train_iters: 5000
  valid_iters: 50
  test_iters: 1000

  eval_steps: 100
  save_steps: 1000

  batch_size: 32
  optimizer: adamax   # adam, sgd, adamax
  learning_rate: 0.001
  clip_grad_norm: 5