# config file

dataset:
  h5_path: data/aapd.h5
  data_path: data/aapd.pickle
  meta_data_path: data/aapd.pickle.meta
  doc_rep_path: data/aapd_doc_qt_rep.pt

global:
  random_seed: 123
  num_data_workers: 16

  max_sent_length: 20
  max_sent_num: 40
  max_doc_length: 500
  cand_doc_size: 4

model:
  name: HLWAN_QT      # BiGRU, LW_BiGRU, HAN, HANLG, HLWAN, HLWAN_QT
  hierarchical: True  # same as the model

  use_pretrain: True
  embedding_num: 50000
  embedding_dim: 100
  embedding_path: data/rmsc_word2vec.model.wv.vectors.npy
  embedding_freeze: True

  hidden_size: 100
  label_size: 22    # different with dataset
  dropout_p: 0.2
  layer_norm: true

train:
  num_epochs: 30
  train_iters: 5000
  valid_iters: 50
  test_iters: 1000

  eval_steps: 100
  save_steps: 1000

  batch_size: 32
  optimizer: adamax   # adam, sgd, adamax
  learning_rate: 0.001
  clip_grad_norm: 5